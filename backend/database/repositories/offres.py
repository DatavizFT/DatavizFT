"""
Repository Offres - Acc√®s aux donn√©es des offres d'emploi
Gestion CRUD et requ√™tes avanc√©es pour les offres MongoDB
"""

from datetime import datetime, timedelta
from typing import Any

import structlog
from motor.motor_asyncio import AsyncIOMotorDatabase
from pymongo import DESCENDING
from pymongo.errors import DuplicateKeyError

from ...models.offre import OffreEmploiModel

logger = structlog.get_logger(__name__)


class OffresRepository:
    """Repository pour les offres d'emploi MongoDB"""

    def __init__(self, database: AsyncIOMotorDatabase):
        """
        Initialise le repository

        Args:
            database: Instance de base MongoDB
        """
        self.db = database
        self.collection = database.offres

    async def insert_offre(self, offre: OffreEmploiModel) -> str | None:
        """
        Ins√®re une nouvelle offre

        Args:
            offre: Mod√®le d'offre √† ins√©rer

        Returns:
            ID MongoDB de l'offre cr√©√©e, None si erreur
        """
        try:
            # Conversion en dict avec validation Pydantic
            offre_dict = offre.dict()

            result = await self.collection.insert_one(offre_dict)
            return str(result.inserted_id)

        except DuplicateKeyError:
            print(f"‚ö†Ô∏è Offre d√©j√† existante: {offre.source_id}")
            return None
        except Exception as e:
            print(f"‚ùå Erreur insertion offre: {e}")
            return None

    async def insert_many_offres(self, offres: list[OffreEmploiModel]) -> int:
        """
        Ins√®re plusieurs offres en lot avec d√©duplication

        Args:
            offres: Liste d'offres √† ins√©rer

        Returns:
            Nombre d'offres r√©ellement ins√©r√©es
        """
        if not offres:
            return 0

        # ‚úÖ D√©duplication optimis√©e avec une seule requ√™te
        source_ids = [offre.source_id for offre in offres]

        # R√©cup√©rer tous les source_id existants en une fois
        existing_cursor = self.collection.find(
            {"source_id": {"$in": source_ids}}, {"source_id": 1, "_id": 0}
        )
        existing_source_ids = {doc["source_id"] async for doc in existing_cursor}

        # Filtrer les nouvelles offres
        offres_nouvelles = [
            offre for offre in offres if offre.source_id not in existing_source_ids
        ]

        doublons = len(offres) - len(offres_nouvelles)
        if doublons > 0:
            logger.info(f"{doublons} doublons d√©tect√©s et ignor√©s")

        if not offres_nouvelles:
            logger.info("Aucune nouvelle offre √† ins√©rer")
            return 0

        try:
            # Conversion en dicts pour nouvelles offres uniquement
            offres_dicts = [offre.dict() for offre in offres_nouvelles]

            result = await self.collection.insert_many(
                offres_dicts,
                ordered=False,  # Continue m√™me si certaines √©chouent
            )

            nb_inserees = len(result.inserted_ids)
            logger.info(
                f"{nb_inserees} nouvelles offres ins√©r√©es, {doublons} doublons ignor√©s"
            )
            return nb_inserees

        except Exception as e:
            logger.error(f"Erreur insertion batch: {e}")
            return 0

    async def get_offre_by_source_id(self, source_id: str) -> dict[str, Any] | None:
        """
        R√©cup√®re une offre par son ID source

        Args:
            source_id: ID de l'offre dans le syst√®me source

        Returns:
            Document offre ou None si pas trouv√©e
        """
        return await self.collection.find_one({"source_id": source_id})

    async def get_offres_recentes(
        self, jours: int = 7, limit: int = 100
    ) -> list[dict[str, Any]]:
        """
        R√©cup√®re les offres r√©centes

        Args:
            jours: Nombre de jours de recul
            limit: Limite du nombre de r√©sultats

        Returns:
            Liste des offres r√©centes
        """
        date_limite = datetime.now() - timedelta(days=jours)

        cursor = (
            self.collection.find({"date_creation": {"$gte": date_limite}})
            .sort("date_creation", DESCENDING)
            .limit(limit)
        )

        return await cursor.to_list(length=limit)

    async def get_toutes_offres(self, limit: int = 10000) -> list[dict[str, Any]]:
        """
        R√©cup√®re toutes les offres (pour s√©ries temporelles long terme)

        Args:
            limit: Limite du nombre de r√©sultats

        Returns:
            Liste de toutes les offres tri√©es par date de cr√©ation
        """
        logger.info(f"R√©cup√©ration de toutes les offres (limite: {limit})")

        cursor = (
            self.collection.find({})  # Pas de filtre de date
            .sort("date_creation", DESCENDING)  # Plus r√©centes en premier
            .limit(limit)
        )

        offres = await cursor.to_list(length=limit)
        logger.info(f"{len(offres)} offres r√©cup√©r√©es pour analyse time series")
        return offres

    async def get_offres_par_periode(
        self,
        date_debut: datetime | None = None,
        date_fin: datetime | None = None,
        limit: int = 10000,
    ) -> list[dict[str, Any]]:
        """
        R√©cup√®re les offres sur une p√©riode sp√©cifique pour time series

        Args:
            date_debut: Date de d√©but (incluse)
            date_fin: Date de fin (incluse)
            limit: Limite du nombre de r√©sultats

        Returns:
            Liste des offres dans la p√©riode tri√©es par date
        """
        query = {}

        if date_debut or date_fin:
            query["date_creation"] = {}
            if date_debut:
                query["date_creation"]["$gte"] = date_debut
            if date_fin:
                query["date_creation"]["$lte"] = date_fin

        logger.info(f"R√©cup√©ration offres p√©riode {date_debut} -> {date_fin}")

        cursor = (
            self.collection.find(query).sort("date_creation", DESCENDING).limit(limit)
        )

        offres = await cursor.to_list(length=limit)
        logger.info(f"{len(offres)} offres trouv√©es dans la p√©riode")
        return offres

    async def get_offres_by_competence(
        self, competence: str, limit: int = 50
    ) -> list[dict[str, Any]]:
        """
        R√©cup√®re les offres contenant une comp√©tence sp√©cifique

        Args:
            competence: Nom de la comp√©tence recherch√©e
            limit: Nombre maximum d'offres

        Returns:
            Liste des offres avec cette comp√©tence
        """
        cursor = (
            self.collection.find({"competences_extraites": competence.lower()})
            .sort("date_creation", DESCENDING)
            .limit(limit)
        )

        return await cursor.to_list(length=limit)

    async def get_offres_by_localisation(
        self,
        departement: str | None = None,
        region: str | None = None,
        limit: int = 50,
    ) -> list[dict[str, Any]]:
        """
        R√©cup√®re les offres par localisation

        Args:
            departement: Code d√©partement (ex: "75")
            region: Code r√©gion (ex: "11")
            limit: Nombre maximum d'offres

        Returns:
            Liste des offres dans la zone g√©ographique
        """
        query = {}

        if departement:
            query["localisation.departement"] = departement
        elif region:
            query["localisation.region"] = region

        cursor = (
            self.collection.find(query).sort("date_creation", DESCENDING).limit(limit)
        )
        return await cursor.to_list(length=limit)

    async def count_offres_by_competences(
        self, competences: list[str]
    ) -> dict[str, int]:
        """
        Compte les offres pour chaque comp√©tence

        Args:
            competences: Liste de comp√©tences √† compter

        Returns:
            Dictionnaire {competence: nombre_offres}
        """
        pipeline = [
            {"$match": {"competences_extraites": {"$in": competences}}},
            {"$unwind": "$competences_extraites"},
            {"$match": {"competences_extraites": {"$in": competences}}},
            {"$group": {"_id": "$competences_extraites", "count": {"$sum": 1}}},
        ]

        cursor = self.collection.aggregate(pipeline)
        results = await cursor.to_list(length=None)

        return {result["_id"]: result["count"] for result in results}

    async def get_stats_temporelles(
        self,
        competence: str | None = None,
        groupby: str = "month",  # "day", "week", "month"
    ) -> list[dict[str, Any]]:
        """
        R√©cup√®re les statistiques temporelles d'√©volution

        Args:
            competence: Comp√©tence sp√©cifique (optionnel)
            groupby: Granularit√© temporelle

        Returns:
            Statistiques temporelles
        """
        # Format de groupe selon la granularit√©
        group_formats = {
            "day": {
                "year": {"$year": "$date_creation"},
                "month": {"$month": "$date_creation"},
                "day": {"$dayOfMonth": "$date_creation"},
            },
            "week": {
                "year": {"$year": "$date_creation"},
                "week": {"$week": "$date_creation"},
            },
            "month": {
                "year": {"$year": "$date_creation"},
                "month": {"$month": "$date_creation"},
            },
        }

        match_stage = {}
        if competence:
            match_stage["competences_extraites"] = competence.lower()

        pipeline = [
            {"$match": match_stage},
            {
                "$group": {
                    "_id": group_formats.get(groupby, group_formats["month"]),
                    "nb_offres": {"$sum": 1},
                    "offres_ids": {"$push": "$source_id"},
                }
            },
            {"$sort": {"_id": 1}},
        ]

        cursor = self.collection.aggregate(pipeline)
        return await cursor.to_list(length=None)

    async def delete_anciennes_offres(self, jours: int = 365) -> int:
        """
        Supprime les offres anciennes pour nettoyage

        Args:
            jours: √Çge limite en jours

        Returns:
            Nombre d'offres supprim√©es
        """
        date_limite = datetime.now() - timedelta(days=jours)

        result = await self.collection.delete_many(
            {"date_creation": {"$lt": date_limite}}
        )

        print(f"üóëÔ∏è {result.deleted_count} offres anciennes supprim√©es")
        return result.deleted_count

    async def get_collection_stats(self) -> dict[str, Any]:
        """
        Obtient les statistiques de la collection

        Returns:
            Statistiques diverses de la collection
        """
        total_count = await self.collection.count_documents({})

        # Derni√®res offres
        recent_pipeline = [{"$sort": {"date_creation": DESCENDING}}, {"$limit": 1}]
        recent_cursor = self.collection.aggregate(recent_pipeline)
        recent_results = await recent_cursor.to_list(length=1)

        # R√©partition par mois
        monthly_pipeline = [
            {
                "$group": {
                    "_id": {
                        "year": {"$year": "$date_creation"},
                        "month": {"$month": "$date_creation"},
                    },
                    "count": {"$sum": 1},
                }
            },
            {"$sort": {"_id": DESCENDING}},
            {"$limit": 12},
        ]
        monthly_cursor = self.collection.aggregate(monthly_pipeline)
        monthly_stats = await monthly_cursor.to_list(length=12)

        return {
            "total_offres": total_count,
            "derniere_offre": recent_results[0] if recent_results else None,
            "repartition_mensuelle": monthly_stats,
            "collection_name": "offres",
        }
