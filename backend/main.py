"""
DatavizFT - Point d'entr√©e principal
Ex√©cute le pipeline de collecte et d'analyse des offres M1805

Usage:
  python backend/main.py                 # Ex√©cution normale (v√©rification 24h)
  python backend/main.py --force         # Forcer l'ex√©cution
  python backend/main.py --limit 50      # Limiter √† 50 offres
  python backend/main.py --stats         # Afficher les statistiques
"""

import argparse
import os
import sys

# Ajouter le dossier parent au path pour les imports relatifs
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import du nouveau pipeline MongoDB
import asyncio

from backend.pipelines.instances.france_travail_pipeline import FranceTravailPipeline
from backend.tools.logging_config import configure_logging, get_logger


async def afficher_statistiques():
    """Affiche les statistiques du pipeline MongoDB avec logging structur√©"""
    configure_logging()
    logger = get_logger(__name__)

    logger.info(
        "R√©cup√©ration des statistiques du pipeline MongoDB",
        extra={"component": "stats", "pipeline": "M1805_MongoDB"},
    )

    try:
        # Cr√©er le pipeline qui g√®re sa propre connexion
        pipeline = FranceTravailPipeline()
        stats = await pipeline.obtenir_statistiques_mongodb()

        logger.info(
            "Statistiques du pipeline MongoDB M1805",
            extra={
                "code_rome": stats.get("code_rome", "M1805"),
                "nb_offres_total": stats.get("nb_offres_total", 0),
                "nb_competences_total": stats.get("nb_competences_total", 0),
                "stockage": "MongoDB",
                "component": "stats",
            },
        )

        # Affichage format√© pour l'utilisateur
        print("üìä STATISTIQUES PIPELINE MONGODB M1805")
        print("=" * 55)
        print(f"Code ROME: {stats.get('code_rome', 'M1805')}")
        print(f"Offres en base: {stats.get('nb_offres_total', 0):,}")
        print(f"Comp√©tences uniques: {stats.get('nb_competences_total', 0):,}")
        print(f"D√©tections: {stats.get('nb_detections_total', 0):,}")
        print("Stockage: MongoDB Atlas/Local")
        print(f"Derni√®re collecte: {stats.get('derniere_collecte', 'Inconnue')}")

    except Exception as e:
        logger.error(
            "Erreur lors de la r√©cup√©ration des statistiques",
            extra={"error": str(e), "component": "stats"},
            exc_info=True,
        )
        print(f"‚ùå Erreur statistiques: {e}")
    finally:
        # Fermer la connexion si le pipeline a √©t√© cr√©√©
        try:
            if "pipeline" in locals():
                await pipeline.close_database_connection()
        except Exception:
            pass


async def main_avec_limite(limite: int):
    """Ex√©cute le pipeline MongoDB avec une limite d'offres"""
    configure_logging()
    logger = get_logger(__name__)

    logger.warning(
        "Ex√©cution du pipeline MongoDB avec limite",
        extra={"limite": limite, "component": "main", "mode": "limit"},
    )

    try:
        pipeline = FranceTravailPipeline()

        # Ex√©cution avec limite
        resultat = await pipeline.executer_pipeline_complet(
            max_offres=limite,
            forcer_execution=True,  # Forcer car on a sp√©cifi√© une limite
        )

        if resultat["success"]:
            nb_offres = resultat.get("resultats", {}).get("nb_offres_sauvegardees", 0)
            logger.success(
                "Pipeline MongoDB avec limite ex√©cut√© avec succ√®s",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "limit",
                    "limite": limite,
                    "status": "success",
                    "nb_offres": nb_offres,
                },
            )
            logger.info(
                f"{nb_offres} offres collect√©es et sauvegard√©es (limite: {limite})",
                extra={
                    "component": "data_collection",
                    "count": nb_offres,
                    "limite": limite,
                },
            )
            print(
                f"‚úÖ {nb_offres} offres collect√©es et sauvegard√©es en MongoDB (limite: {limite})"
            )
        else:
            error_msg = resultat.get("error", "Erreur inconnue")
            logger.error(
                "Erreur lors de l'ex√©cution du pipeline avec limite",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "limit",
                    "limite": limite,
                    "status": "failed",
                    "error": error_msg,
                },
            )
            print(f"‚ùå Erreur pipeline: {error_msg}")

    except Exception as e:
        logger.critical(
            "Erreur fatale lors de l'ex√©cution avec limite",
            extra={
                "error": str(e),
                "mode": "limit",
                "limite": limite,
                "component": "main",
            },
            exc_info=True,
        )
        print(f"‚ùå Erreur critique: {e}")
    finally:
        try:
            if "pipeline" in locals():
                await pipeline.close_database_connection()
        except Exception:
            pass


async def main_force():
    """Point d'entr√©e pour forcer l'ex√©cution compl√®te du pipeline MongoDB"""
    configure_logging()
    logger = get_logger(__name__)

    logger.warning(
        "D√©marrage forc√© du pipeline MongoDB (collecte compl√®te)",
        extra={"mode": "force", "component": "main"},
    )

    try:
        pipeline = FranceTravailPipeline()

        # Ex√©cuter le pipeline MongoDB complet forc√©
        resultat = await pipeline.executer_pipeline_complet(
            max_offres=None, forcer_execution=True  # Aucune limite - toutes les offres API
        )

        if resultat["success"]:
            resultats_details = resultat.get("resultats", {})
            nb_offres = resultats_details.get("nb_offres_sauvegardees", 0)
            nb_competences = resultats_details.get("nb_competences_extraites", 0)

            logger.success(
                "Pipeline MongoDB forc√© ex√©cut√© avec succ√®s",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "force",
                    "status": "success",
                    "nb_offres": nb_offres,
                    "nb_competences": nb_competences,
                },
            )
            logger.info(
                f"{nb_offres} offres M1805 collect√©es et sauvegard√©es en MongoDB",
                extra={"component": "data_collection", "count": nb_offres},
            )
            logger.info(
                f"{nb_competences} comp√©tences extraites et analys√©es",
                extra={"component": "competence_analysis", "count": nb_competences},
            )
            logger.info(
                "Donn√©es sauvegard√©es dans MongoDB",
                extra={"component": "database_output", "location": "MongoDB"},
            )

            print(
                f"‚úÖ Pipeline forc√© termin√©: {nb_offres} offres, {nb_competences} comp√©tences"
            )
        else:
            error_msg = resultat.get("error", "Erreur inconnue")
            logger.error(
                "Erreur lors de l'ex√©cution du pipeline forc√©",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "force",
                    "status": "failed",
                    "error": error_msg,
                },
            )
            print(f"‚ùå Erreur pipeline forc√©: {error_msg}")

    except Exception as e:
        logger.critical(
            "Erreur fatale lors de l'ex√©cution forc√©e",
            extra={"error": str(e), "mode": "force", "component": "main"},
            exc_info=True,
        )
        print(f"‚ùå Erreur critique: {e}")
    finally:
        try:
            if "pipeline" in locals():
                await pipeline.close_database_connection()
        except Exception:
            pass


async def main_force_analyses():
    """Forcer l'analyse des comp√©tences et la g√©n√©ration des statistiques"""
    configure_logging()
    logger = get_logger(__name__)

    logger.warning(
        "D√©marrage forc√© des analyses (comp√©tences + statistiques)",
        extra={"mode": "force_analyses", "component": "main"},
    )

    try:
        pipeline = FranceTravailPipeline()

        # Ex√©cuter le pipeline avec forcer_analyses=True
        resultat = await pipeline.executer_pipeline_complet(
            max_offres=None,  # Aucune limite
            forcer_execution=False,  # Ne pas forcer la collecte
            forcer_analyses=True,  # Forcer les analyses
        )

        if resultat.get("success", False):
            nb_offres = resultat.get("nb_offres_analysees", 0)
            nb_competences = resultat.get("nb_competences_detectees", 0)
            top_competences = resultat.get("top_competences", [])

            logger.info(
                "‚úÖ Analyses forc√©es termin√©es avec succ√®s",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "force_analyses",
                    "status": "success",
                    "nb_offres": nb_offres,
                    "nb_competences": nb_competences,
                },
            )

            print(f"üìä Analyses forc√©es termin√©es: {nb_offres} offres analys√©es")
            print(f"üß† {nb_competences} comp√©tences d√©tect√©es")

            if top_competences:
                print("üèÜ Top 5 comp√©tences:")
                for i, comp in enumerate(top_competences[:5], 1):
                    nom = comp.get("competence", "Unknown")
                    pct = comp.get("pourcentage", 0)
                    print(f"   {i}. {nom}: {pct}%")
        else:
            error_msg = resultat.get("error", "Erreur inconnue")
            logger.error(
                "Erreur lors des analyses forc√©es",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "force_analyses",
                    "status": "failed",
                    "error": error_msg,
                },
            )
            print(f"‚ùå Erreur analyses: {error_msg}")

    except Exception as e:
        logger.critical(
            "Erreur fatale lors des analyses forc√©es",
            extra={"error": str(e), "mode": "force_analyses", "component": "main"},
            exc_info=True,
        )
        print(f"‚ùå Erreur critique: {e}")
    finally:
        try:
            if "pipeline" in locals():
                await pipeline.close_database_connection()
        except Exception:
            pass


async def main():
    """Point d'entr√©e principal - Lance le pipeline MongoDB avec v√©rification intelligente"""
    configure_logging()
    logger = get_logger(__name__)

    logger.info(
        "D√©marrage du pipeline MongoDB DatavizFT",
        extra={"mode": "normal", "component": "main"},
    )

    try:
        pipeline = FranceTravailPipeline()

        # V√©rifier si une collecte r√©cente existe
        derniere_collecte = await pipeline.verifier_collecte_recente()

        if derniere_collecte and not derniere_collecte.get("doit_collecter", True):
            logger.info(
                "Pipeline ignor√© - collecte r√©cente d√©tect√©e en MongoDB",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "normal",
                    "status": "skipped",
                    "derniere_collecte": derniere_collecte.get("date_collecte"),
                    "nb_offres_existantes": derniere_collecte.get("nb_offres", 0),
                },
            )
            print(
                f"‚è≠Ô∏è Collecte r√©cente trouv√©e: {derniere_collecte.get('nb_offres', 0)} offres"
            )
            print(
                f"   Derni√®re collecte: {derniere_collecte.get('date_collecte', 'Inconnue')}"
            )
            print("   Utilisez --force pour forcer une nouvelle collecte")
            return

        # Ex√©cuter le pipeline complet avec v√©rification automatique
        resultat = await pipeline.executer_pipeline_complet(
            max_offres=None,  # Collecte non-mod√©r√©e par d√©faut
            forcer_execution=False,  # Respecter la v√©rification 24h
        )

        if resultat["success"]:
            # Le pipeline retourne directement les donn√©es, pas dans une enveloppe "resultats"
            nb_offres = resultat.get("nb_offres_sauvegardees", 0)
            nb_competences = resultat.get("nb_competences_detectees", 0)

            logger.success(
                "Pipeline MongoDB ex√©cut√© avec succ√®s",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "normal",
                    "status": "success",
                    "nb_offres": nb_offres,
                    "nb_competences": nb_competences,
                },
            )
            logger.info(
                f"{nb_offres} nouvelles offres M1805 collect√©es et sauvegard√©es",
                extra={
                    "component": "data_collection",
                    "count": nb_offres,
                },
            )
            logger.info(
                f"{nb_competences} comp√©tences extraites et analys√©es",
                extra={"component": "competence_analysis", "count": nb_competences},
            )
            logger.info(
                "Donn√©es persist√©es dans MongoDB",
                extra={"component": "database_output", "location": "MongoDB"},
            )

            print(
                f"‚úÖ Pipeline termin√©: {nb_offres} nouvelles offres, {nb_competences} comp√©tences"
            )
            print("üìä Consultez MongoDB pour les donn√©es compl√®tes")
        else:
            error_msg = resultat.get("error", "Erreur inconnue")
            logger.error(
                "Erreur lors de l'ex√©cution du pipeline",
                extra={
                    "pipeline": "france_travail_mongodb",
                    "mode": "normal",
                    "status": "failed",
                    "error": error_msg,
                },
            )
            print(f"‚ùå Erreur pipeline: {error_msg}")

    except Exception as e:
        logger.critical(
            "Erreur fatale lors de l'ex√©cution",
            extra={"error": str(e), "mode": "normal", "component": "main"},
            exc_info=True,
        )
        print(f"‚ùå Erreur critique: {e}")
    finally:
        try:
            if "pipeline" in locals():
                await pipeline.close_database_connection()
        except Exception:
            pass


def parse_arguments():
    """Parse les arguments de ligne de commande"""
    parser = argparse.ArgumentParser(
        description="Pipeline DatavizFT M1805 - Collecte et analyse des offres d'emploi",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python backend/main.py                 # Ex√©cution normale
  python backend/main.py --force         # Forcer l'ex√©cution compl√®te
  python backend/main.py --force-analyses   # Forcer seulement les analyses
  python backend/main.py --limit 50      # Limiter √† 50 offres
  python backend/main.py --stats         # Afficher les statistiques
        """,
    )

    parser.add_argument(
        "--force",
        action="store_true",
        help="Forcer l'ex√©cution (ignore la v√©rification 24h)",
    )

    parser.add_argument(
        "--force-analyses",
        action="store_true",
        help="Forcer l'analyse des comp√©tences et g√©n√©ration des statistiques",
    )

    parser.add_argument(
        "--limit", type=int, help="Limiter le nombre d'offres collect√©es"
    )

    parser.add_argument(
        "--stats", action="store_true", help="Afficher les statistiques du pipeline"
    )

    return parser.parse_args()


async def run_main():
    """Point d'entr√©e asynchrone principal"""
    args = parse_arguments()

    if args.stats:
        await afficher_statistiques()
    elif args.force_analyses:
        await main_force_analyses()
    elif args.limit:
        await main_avec_limite(args.limit)
    elif args.force:
        await main_force()
    else:
        await main()


if __name__ == "__main__":
    try:
        asyncio.run(run_main())
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Pipeline interrompu par l'utilisateur")
    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {e}")
        sys.exit(1)
